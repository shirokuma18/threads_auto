#!/usr/bin/env python3
"""
Threads API äºˆç´„æŠ•ç¨¿ + PDCAåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3æ—¥ã‚µã‚¤ã‚¯ãƒ«ã§PDCAã‚’å›ã™ã“ã¨ã«ç‰¹åŒ–
"""

import csv
import time
import requests
import json
from datetime import datetime, timedelta
from collections import defaultdict
import os
import sys

# ============================================
# è¨­å®šé …ç›®
# ============================================
ACCESS_TOKEN = os.getenv('THREADS_ACCESS_TOKEN', 'YOUR_ACCESS_TOKEN_HERE')
USER_ID = os.getenv('THREADS_USER_ID', 'YOUR_USER_ID_HERE')

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
CSV_FILE = 'posts_schedule.csv'
LOG_FILE = 'posted_log.json'
ANALYTICS_FILE = 'analytics_data.csv'
PDCA_REPORT_FILE = 'pdca_report.md'

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
MIN_INTERVAL_SECONDS = 3600  # 1æ™‚é–“

# ============================================
# Threads API
# ============================================
API_BASE_URL = 'https://graph.threads.net/v1.0'


def create_threads_post(text):
    """Threads APIã§æŠ•ç¨¿ã‚’ä½œæˆ"""
    try:
        create_url = f'{API_BASE_URL}/{USER_ID}/threads'
        create_params = {
            'media_type': 'TEXT',
            'text': text,
            'access_token': ACCESS_TOKEN
        }
        
        print(f"  â†’ ã‚³ãƒ³ãƒ†ãƒŠä½œæˆä¸­...")
        create_response = requests.post(create_url, params=create_params)
        create_response.raise_for_status()
        container_id = create_response.json().get('id')
        
        if not container_id:
            print(f"  âœ— ã‚³ãƒ³ãƒ†ãƒŠIDã®å–å¾—ã«å¤±æ•—")
            return None
        
        publish_url = f'{API_BASE_URL}/{USER_ID}/threads_publish'
        publish_params = {
            'creation_id': container_id,
            'access_token': ACCESS_TOKEN
        }
        
        print(f"  â†’ æŠ•ç¨¿å…¬é–‹ä¸­...")
        publish_response = requests.post(publish_url, params=publish_params)
        publish_response.raise_for_status()
        
        post_id = publish_response.json().get('id')
        if post_id:
            print(f"  âœ“ æŠ•ç¨¿æˆåŠŸï¼ (ID: {post_id})")
            return post_id
        else:
            print(f"  âœ— æŠ•ç¨¿IDã®å–å¾—ã«å¤±æ•—")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"  âœ— API ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def get_post_insights(post_id):
    """æŠ•ç¨¿ã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        url = f'{API_BASE_URL}/{post_id}'
        params = {
            'fields': 'id,text,timestamp,permalink',
            'access_token': ACCESS_TOKEN
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        
        insights_url = f'{API_BASE_URL}/{post_id}/insights'
        insights_params = {
            'metric': 'views,likes,replies,reposts,quotes',
            'access_token': ACCESS_TOKEN
        }
        
        insights_response = requests.get(insights_url, params=insights_params)
        
        insights_data = {}
        if insights_response.status_code == 200:
            insights = insights_response.json().get('data', [])
            for metric in insights:
                insights_data[metric['name']] = metric.get('values', [{}])[0].get('value', 0)
        
        result = {
            'post_id': post_id,
            'text': data.get('text', ''),
            'timestamp': data.get('timestamp', ''),
            'permalink': data.get('permalink', ''),
            'views': insights_data.get('views', 0),
            'likes': insights_data.get('likes', 0),
            'replies': insights_data.get('replies', 0),
            'reposts': insights_data.get('reposts', 0),
            'quotes': insights_data.get('quotes', 0),
        }
        
        total_engagement = (
            result['likes'] + 
            result['replies'] + 
            result['reposts'] + 
            result['quotes']
        )
        result['engagement'] = total_engagement
        result['engagement_rate'] = (
            (total_engagement / result['views'] * 100) 
            if result['views'] > 0 else 0
        )
        
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"  âœ— åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


# ============================================
# CSV & ãƒ­ã‚°ç®¡ç†
# ============================================

def load_schedule():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    posts = []
    try:
        with open(CSV_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                posts.append({
                    'id': row.get('id', ''),
                    'datetime': row.get('datetime', ''),
                    'text': row.get('text', '')
                })
    except FileNotFoundError:
        print(f"è­¦å‘Š: {CSV_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    return posts


def load_posted_log():
    """æŠ•ç¨¿æ¸ˆã¿ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_posted_log(log):
    """æŠ•ç¨¿æ¸ˆã¿ãƒ­ã‚°ã‚’ä¿å­˜"""
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump(log, f, ensure_ascii=False, indent=2)


def save_analytics_to_csv(analytics_data):
    """åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ä¿å­˜"""
    file_exists = os.path.exists(ANALYTICS_FILE)
    
    fieldnames = [
        'timestamp', 'post_id', 'text', 'posted_hour', 'posted_day',
        'views', 'likes', 'replies', 'reposts', 'quotes', 
        'engagement', 'engagement_rate', 'char_count', 'has_emoji'
    ]
    
    with open(ANALYTICS_FILE, 'a', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        
        if not file_exists:
            writer.writeheader()
        
        # æŠ•ç¨¿æ™‚é–“ã‹ã‚‰æ™‚é–“å¸¯ã¨æ›œæ—¥ã‚’æŠ½å‡º
        posted_time = datetime.fromisoformat(analytics_data.get('timestamp', '').replace('Z', '+00:00'))
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
        text = analytics_data.get('text', '')
        has_emoji = any(ord(c) > 127 for c in text)  # ç°¡æ˜“çš„ãªçµµæ–‡å­—åˆ¤å®š
        
        writer.writerow({
            'timestamp': datetime.now().isoformat(),
            'post_id': analytics_data.get('post_id', ''),
            'text': text[:100],
            'posted_hour': posted_time.hour,
            'posted_day': posted_time.strftime('%A'),
            'views': analytics_data.get('views', 0),
            'likes': analytics_data.get('likes', 0),
            'replies': analytics_data.get('replies', 0),
            'reposts': analytics_data.get('reposts', 0),
            'quotes': analytics_data.get('quotes', 0),
            'engagement': analytics_data.get('engagement', 0),
            'engagement_rate': f"{analytics_data.get('engagement_rate', 0):.2f}",
            'char_count': len(text),
            'has_emoji': has_emoji
        })


# ============================================
# PDCAåˆ†ææ©Ÿèƒ½
# ============================================

def generate_3day_report():
    """
    éå»3æ—¥é–“ã®PDCAãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    """
    print("\n" + "="*70)
    print("ğŸ“Š éå»3æ—¥é–“ã®PDCAãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    print("="*70)
    
    # éå»3æ—¥é–“ã®æŠ•ç¨¿ã‚’å–å¾—
    posted_log = load_posted_log()
    three_days_ago = datetime.now() - timedelta(days=3)
    
    recent_posts = []
    for post_id, post_data in posted_log.items():
        posted_at = datetime.fromisoformat(post_data.get('posted_at', ''))
        if posted_at >= three_days_ago and 'threads_post_id' in post_data:
            recent_posts.append({
                'csv_id': post_id,
                'threads_id': post_data['threads_post_id'],
                'text': post_data['text'],
                'posted_at': posted_at,
                'scheduled_at': post_data.get('scheduled_at', '')
            })
    
    if not recent_posts:
        print("âš ï¸  éå»3æ—¥é–“ã®æŠ•ç¨¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\néå»3æ—¥é–“ã®æŠ•ç¨¿æ•°: {len(recent_posts)}ä»¶")
    print("åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...\n")
    
    # å„æŠ•ç¨¿ã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    analytics_results = []
    for i, post in enumerate(recent_posts, 1):
        print(f"[{i}/{len(recent_posts)}] æŠ•ç¨¿ {post['csv_id']} ã‚’åˆ†æä¸­...")
        analytics = get_post_insights(post['threads_id'])
        if analytics:
            analytics['posted_at'] = post['posted_at']
            analytics['csv_id'] = post['csv_id']
            analytics_results.append(analytics)
            save_analytics_to_csv(analytics)
            print(f"  âœ“ å®Œäº†")
        time.sleep(2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
    
    if not analytics_results:
        print("âš ï¸  åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = generate_pdca_markdown(analytics_results)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(PDCA_REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ {PDCA_REPORT_FILE} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print("\n" + report)
    
    return report


def generate_pdca_markdown(analytics_results):
    """
    PDCAãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ç”Ÿæˆ
    """
    # åŸºæœ¬çµ±è¨ˆ
    total_posts = len(analytics_results)
    total_views = sum(a['views'] for a in analytics_results)
    total_engagement = sum(a['engagement'] for a in analytics_results)
    avg_engagement_rate = sum(a['engagement_rate'] for a in analytics_results) / total_posts
    
    # æ™‚é–“å¸¯åˆ¥åˆ†æ
    hourly_performance = defaultdict(lambda: {'count': 0, 'engagement_rate': 0})
    for a in analytics_results:
        hour = a['posted_at'].hour
        hourly_performance[hour]['count'] += 1
        hourly_performance[hour]['engagement_rate'] += a['engagement_rate']
    
    for hour in hourly_performance:
        hourly_performance[hour]['avg_engagement_rate'] = (
            hourly_performance[hour]['engagement_rate'] / 
            hourly_performance[hour]['count']
        )
    
    # ãƒ™ã‚¹ãƒˆæ™‚é–“å¸¯
    best_hours = sorted(
        hourly_performance.items(),
        key=lambda x: x[1]['avg_engagement_rate'],
        reverse=True
    )[:3]
    
    # ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿
    top_posts = sorted(analytics_results, key=lambda x: x['engagement_rate'], reverse=True)[:3]
    worst_posts = sorted(analytics_results, key=lambda x: x['engagement_rate'])[:3]
    
    # æ–‡å­—æ•°åˆ†æ
    char_counts = [len(a['text']) for a in analytics_results]
    avg_char_count = sum(char_counts) / len(char_counts) if char_counts else 0
    
    # çµµæ–‡å­—ä½¿ç”¨ã®åŠ¹æœ
    with_emoji = [a for a in analytics_results if any(ord(c) > 127 for c in a['text'])]
    without_emoji = [a for a in analytics_results if not any(ord(c) > 127 for c in a['text'])]
    
    emoji_effect = ""
    if with_emoji and without_emoji:
        avg_with_emoji = sum(a['engagement_rate'] for a in with_emoji) / len(with_emoji)
        avg_without_emoji = sum(a['engagement_rate'] for a in without_emoji) / len(without_emoji)
        emoji_diff = avg_with_emoji - avg_without_emoji
        emoji_effect = f"çµµæ–‡å­—ã‚ã‚Š: {avg_with_emoji:.2f}% vs ãªã—: {avg_without_emoji:.2f}% (å·®: {emoji_diff:+.2f}%)"
    
    # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    now = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
    
    report = f"""# ğŸ“Š Threads PDCA ãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {now}  
**åˆ†ææœŸé–“**: éå»3æ—¥é–“  
**æŠ•ç¨¿æ•°**: {total_posts}ä»¶

---

## ğŸ“ˆ ã‚µãƒãƒªãƒ¼

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| **ç·è¡¨ç¤ºå›æ•°** | {total_views:,} |
| **ç·ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ** | {total_engagement:,} |
| **å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡** | {avg_engagement_rate:.2f}% |
| **å¹³å‡æ–‡å­—æ•°** | {avg_char_count:.0f}æ–‡å­— |

---

## ğŸ† ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿

"""
    
    for i, post in enumerate(top_posts, 1):
        report += f"""### {i}ä½: {post['engagement_rate']:.2f}%

- **ãƒ†ã‚­ã‚¹ãƒˆ**: {post['text'][:80]}...
- **è¡¨ç¤ºå›æ•°**: {post['views']:,}
- **ã„ã„ã­**: {post['likes']:,} | **è¿”ä¿¡**: {post['replies']:,} | **ãƒªãƒã‚¹ãƒˆ**: {post['reposts']:,}
- **æŠ•ç¨¿æ™‚åˆ»**: {post['posted_at'].strftime('%m/%d %H:%M')}

"""
    
    report += f"""---

## â° ãƒ™ã‚¹ãƒˆæŠ•ç¨¿æ™‚é–“å¸¯

"""
    
    for i, (hour, data) in enumerate(best_hours, 1):
        report += f"{i}. **{hour:02d}æ™‚å°**: ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ {data['avg_engagement_rate']:.2f}% (æŠ•ç¨¿æ•°: {data['count']}ä»¶)\n"
    
    report += f"""

---

## ğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ

### æ–‡å­—æ•°
- **å¹³å‡æ–‡å­—æ•°**: {avg_char_count:.0f}æ–‡å­—
- **æœ€çŸ­**: {min(char_counts)}æ–‡å­— | **æœ€é•·**: {max(char_counts)}æ–‡å­—

### çµµæ–‡å­—ã®åŠ¹æœ
{emoji_effect if emoji_effect else "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}

---

## âš ï¸ æ”¹å–„ãŒå¿…è¦ãªæŠ•ç¨¿

"""
    
    for i, post in enumerate(worst_posts, 1):
        report += f"""{i}. **{post['engagement_rate']:.2f}%** - {post['text'][:60]}...
"""
    
    report += f"""

---

## ğŸ’¡ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ (Plan)

### âœ… ç¶šã‘ã‚‹ã“ã¨ (Keep)

"""
    
    # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    if best_hours:
        best_hour = best_hours[0][0]
        report += f"1. **{best_hour:02d}æ™‚å°ã®æŠ•ç¨¿ã‚’å¢—ã‚„ã™** - æœ€ã‚‚åå¿œãŒè‰¯ã„æ™‚é–“å¸¯ã§ã™\n"
    
    if top_posts:
        top_post = top_posts[0]
        if len(top_post['text']) < 100:
            report += f"2. **çŸ­ã‚ã®æŠ•ç¨¿ãŒå¥½èª¿** - {len(top_post['text'])}æ–‡å­—ç¨‹åº¦ãŒåŠ¹æœçš„\n"
        else:
            report += f"2. **é•·æ–‡æŠ•ç¨¿ãŒå¥½èª¿** - {len(top_post['text'])}æ–‡å­—ç¨‹åº¦ã®è©³ç´°ãªå†…å®¹ãŒåŠ¹æœçš„\n"
    
    if emoji_effect and "+" in emoji_effect:
        report += "3. **çµµæ–‡å­—ã®ä½¿ç”¨ã‚’ç¶™ç¶š** - ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãŒé«˜ã„å‚¾å‘\n"
    
    report += f"""

### ğŸ”„ æ”¹å–„ã™ã‚‹ã“ã¨ (Improve)

"""
    
    # æ”¹å–„ææ¡ˆ
    if worst_posts:
        report += f"1. **ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã®åˆ†æ** - ãªãœåå¿œãŒæ‚ªã‹ã£ãŸã®ã‹æŒ¯ã‚Šè¿”ã‚‹\n"
    
    if best_hours and len(best_hours) > 0:
        avoid_hours = [h for h in range(24) if h not in [bh[0] for bh in best_hours[:5]]]
        if avoid_hours:
            report += f"2. **æŠ•ç¨¿æ™‚é–“ã®æœ€é©åŒ–** - {avoid_hours[0]:02d}æ™‚å°ãªã©ã¯é¿ã‘ã‚‹\n"
    
    report += f"""

### ğŸ†• è©¦ã™ã“ã¨ (Try)

1. **æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‚’è©¦ã™** - è³ªå•å½¢å¼ã€æŠ•ç¥¨ã€ãƒªã‚¹ãƒˆå½¢å¼ãªã©
2. **ç•°ãªã‚‹æ™‚é–“å¸¯ã«ãƒ†ã‚¹ãƒˆæŠ•ç¨¿** - ã¾ã è©¦ã—ã¦ã„ãªã„æ™‚é–“å¸¯ã‚’æ¢ã‚‹
3. **ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®åŠ¹æœã‚’æ¤œè¨¼** - ä½¿ç”¨æœ‰ç„¡ã§A/Bãƒ†ã‚¹ãƒˆ

---

## ğŸ“… æ¬¡ã®3æ—¥é–“ã®æŠ•ç¨¿ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆ

æ¨å¥¨æŠ•ç¨¿æ™‚åˆ»:
"""
    
    # æ¬¡ã®3æ—¥é–“ã®æ¨å¥¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    for day in range(1, 4):
        date = (datetime.now() + timedelta(days=day)).strftime('%Y-%m-%d')
        if best_hours:
            for hour, _ in best_hours[:2]:  # ãƒˆãƒƒãƒ—2ã®æ™‚é–“å¸¯
                report += f"- {date} {hour:02d}:00\n"
    
    report += f"""

---

## ğŸ”— è©³ç´°ãƒ‡ãƒ¼ã‚¿

è©³ç´°ãªåˆ†æãƒ‡ãƒ¼ã‚¿ã¯ `{ANALYTICS_FILE}` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

**æ¬¡å›ãƒ¬ãƒãƒ¼ãƒˆ**: 3æ—¥å¾Œ

"""
    
    return report


def suggest_next_posts():
    """
    æ¬¡ã®æŠ•ç¨¿IDã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ææ¡ˆ
    """
    posts = load_schedule()
    
    if not posts:
        next_id = 1
    else:
        max_id = max(int(p['id']) for p in posts if p['id'].isdigit())
        next_id = max_id + 1
    
    # éå»ã®åˆ†æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªæ™‚é–“ã‚’ææ¡ˆ
    best_times = []
    if os.path.exists(ANALYTICS_FILE):
        with open(ANALYTICS_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            hourly_rates = defaultdict(list)
            for row in reader:
                try:
                    hour = int(row['posted_hour'])
                    rate = float(row['engagement_rate'])
                    hourly_rates[hour].append(rate)
                except:
                    continue
            
            # å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãŒé«˜ã„æ™‚é–“å¸¯
            avg_rates = {h: sum(rates)/len(rates) for h, rates in hourly_rates.items()}
            best_times = sorted(avg_rates.items(), key=lambda x: x[1], reverse=True)[:3]
    
    print("\n" + "="*70)
    print("ğŸ“ æ¬¡ã®æŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
    print("="*70)
    print(f"\næ¬¡ã®ID: {next_id}")
    
    if best_times:
        print("\næ¨å¥¨æŠ•ç¨¿æ™‚é–“:")
        for hour, rate in best_times:
            print(f"  - {hour:02d}:00 (å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {rate:.2f}%)")
    
    # CSVãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
    tomorrow = datetime.now() + timedelta(days=1)
    csv_template = "\n# æ¬¡ã®æŠ•ç¨¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼ˆä»¥ä¸‹ã®è¡Œã‚’ã‚³ãƒ”ãƒ¼ï¼‰\n"
    
    for i in range(3):  # 3æ—¥åˆ†
        date = (tomorrow + timedelta(days=i)).strftime('%Y-%m-%d')
        if best_times:
            for j, (hour, _) in enumerate(best_times[:2]):  # 1æ—¥2å›
                csv_template += f"{next_id + i*2 + j},{date} {hour:02d}:00,ã“ã“ã«æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›\n"
        else:
            csv_template += f"{next_id + i},{date} 09:00,ã“ã“ã«æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›\n"
            csv_template += f"{next_id + i + 1},{date} 18:00,ã“ã“ã«æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›\n"
    
    print(csv_template)
    print("\n" + "="*70)


# ============================================
# æŠ•ç¨¿å‡¦ç†
# ============================================

def check_and_post():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æŠ•ç¨¿"""
    posts = load_schedule()
    posted_log = load_posted_log()
    current_time = datetime.now()
    
    posts_to_do = []
    
    for post in posts:
        post_id = post['id']
        
        if post_id in posted_log:
            continue
        
        try:
            scheduled_time = datetime.strptime(post['datetime'], '%Y-%m-%d %H:%M')
        except ValueError:
            print(f"è­¦å‘Š: ç„¡åŠ¹ãªæ—¥æ™‚å½¢å¼ (ID: {post_id}): {post['datetime']}")
            continue
        
        if current_time >= scheduled_time:
            posts_to_do.append({
                'id': post_id,
                'scheduled_time': scheduled_time,
                'text': post['text']
            })
    
    posts_to_do.sort(key=lambda x: x['scheduled_time'])
    
    if not posts_to_do:
        print("æŠ•ç¨¿å¾…ã¡ã®é …ç›®ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\næŠ•ç¨¿å¾…ã¡: {len(posts_to_do)}ä»¶")
    
    for i, post in enumerate(posts_to_do):
        post_id = post['id']
        text = post['text']
        
        print(f"\n[{i+1}/{len(posts_to_do)}] æŠ•ç¨¿ID: {post_id}")
        print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text[:50]}{'...' if len(text) > 50 else ''}")
        
        threads_post_id = create_threads_post(text)
        
        if threads_post_id:
            posted_log[post_id] = {
                'posted_at': datetime.now().isoformat(),
                'scheduled_at': post['scheduled_time'].isoformat(),
                'text': text,
                'threads_post_id': threads_post_id
            }
            save_posted_log(posted_log)
        
        if i < len(posts_to_do) - 1:
            wait_time = MIN_INTERVAL_SECONDS
            print(f"  â†’ æ¬¡ã®æŠ•ç¨¿ã¾ã§ {wait_time}ç§’å¾…æ©Ÿ...")
            time.sleep(wait_time)


# ============================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================================

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'pdca':
            # PDCAãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            generate_3day_report()
        elif command == 'suggest':
            # æ¬¡ã®æŠ•ç¨¿ã‚’ææ¡ˆ
            suggest_next_posts()
        elif command == 'full-cycle':
            # ãƒ•ãƒ«ã‚µã‚¤ã‚¯ãƒ«ï¼ˆåˆ†æâ†’ææ¡ˆï¼‰
            generate_3day_report()
            suggest_next_posts()
        else:
            print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("  python script.py              # æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯ï¼†å®Ÿè¡Œ")
            print("  python script.py pdca         # 3æ—¥é–“PDCAãƒ¬ãƒãƒ¼ãƒˆ")
            print("  python script.py suggest      # æ¬¡ã®æŠ•ç¨¿ã‚’ææ¡ˆ")
            print("  python script.py full-cycle   # åˆ†æâ†’ææ¡ˆï¼ˆæ¨å¥¨ï¼‰")
    else:
        # æŠ•ç¨¿ãƒ¢ãƒ¼ãƒ‰
        print("=" * 70)
        print("Threads äºˆç´„æŠ•ç¨¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        print("=" * 70)
        check_and_post()


if __name__ == '__main__':
    if ACCESS_TOKEN == 'YOUR_ACCESS_TOKEN_HERE' or USER_ID == 'YOUR_USER_ID_HERE':
        print("\nâš ï¸  èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
        print("ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š")
        print("  export THREADS_ACCESS_TOKEN='your_token'")
        print("  export THREADS_USER_ID='your_user_id'")
        sys.exit(1)
    
    main()
