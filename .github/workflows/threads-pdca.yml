name: Threads PDCA Automation

on:
  # 投稿チェック（5分おきに実行）
  schedule:
    # GitHub Actionsのcronは不安定なため、5分おきに実行
    # 実際の投稿は1日25件制限で制御
    - cron: '*/10 * * * *'

    # 毎朝のレポート投稿（日本時間 9時）
    - cron: '0 0 * * *'

    # 3日ごとにPDCAレポート生成（日本時間 20時）
    - cron: '0 11 */3 * *'

  # 手動実行
  workflow_dispatch:
    inputs:
      mode:
        description: '実行モード'
        required: false
        default: 'post'
        type: choice
        options:
          - post
          - daily-report
          - pdca
          - full-cycle

permissions:
  contents: write

jobs:
  # 投稿ジョブ（1日4回）
  post-threads:
    runs-on: ubuntu-latest
    # 投稿時刻に実行、またはpost/full-cycleモード
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' &&
       (github.event.inputs.mode == 'post' || github.event.inputs.mode == 'full-cycle'))

    steps:
      - name: リポジトリをチェックアウト (automation ブランチ)
        uses: actions/checkout@v3
        with:
          ref: automation
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Python環境をセットアップ
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: 依存関係をインストール
        run: pip install requests

      - name: Git設定
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: データベースを初期化（初回のみ）
        run: |
          if [ ! -f threads.db ]; then
            echo "📦 データベースを初期化中..."
            python3 migrate_to_sqlite.py init
            python3 threads_sqlite.py import --csv posts_schedule.csv
            echo "✅ データベース初期化完了"
          else
            echo "✅ 既存のデータベースを使用"

            # 今日投稿すべきpending投稿数をチェック
            CURRENT_DATE=$(TZ=Asia/Tokyo date '+%Y-%m-%d')
            TODAY_PENDING=$(sqlite3 threads.db "SELECT COUNT(*) FROM posts WHERE status='pending' AND DATE(scheduled_at) = '$CURRENT_DATE'")
            TODAY_POSTED=$(sqlite3 threads.db "SELECT COUNT(*) FROM posts WHERE status='posted' AND DATE(posted_at) = '$CURRENT_DATE'")
            TOTAL_PENDING=$(sqlite3 threads.db "SELECT COUNT(*) FROM posts WHERE status='pending'")

            echo "📊 DB状態: pending $TOTAL_PENDING 件 (今日 $TODAY_PENDING 件) / posted (今日 $TODAY_POSTED 件)"

            # 今日投稿すべきpending投稿がなく、かつ今日のposted投稿もない場合のみリカバリー
            if [ "$TODAY_PENDING" -eq 0 ] && [ "$TODAY_POSTED" -eq 0 ]; then
              echo "⚠️  今日の投稿がありません。CSVから再インポートします。"
              rm -f threads.db
              python3 migrate_to_sqlite.py init
              python3 threads_sqlite.py import --csv posts_schedule.csv
              TODAY_PENDING_NEW=$(sqlite3 threads.db "SELECT COUNT(*) FROM posts WHERE status='pending' AND DATE(scheduled_at) = '$CURRENT_DATE'")
              TOTAL_PENDING_NEW=$(sqlite3 threads.db "SELECT COUNT(*) FROM posts WHERE status='pending'")
              echo "📊 再インポート後: pending $TOTAL_PENDING_NEW 件 (今日 $TODAY_PENDING_NEW 件)"
            elif [ "$TODAY_POSTED" -gt 0 ]; then
              echo "✅ 今日すでに $TODAY_POSTED 件投稿済み。既存DBを使用します。"
            fi
          fi

      - name: 投稿スクリプトを実行
        run: python threads_sqlite.py post
        env:
          THREADS_ACCESS_TOKEN: ${{ secrets.THREADS_ACCESS_TOKEN }}
          THREADS_USER_ID: ${{ secrets.THREADS_USER_ID }}

      - name: 投稿履歴を更新・投稿済みをCSVから削除
        if: always()
        run: |
          if [ -f threads.db ]; then
            # 1. 今日のposted投稿を posted_history.csv に追加
            sqlite3 threads.db -header -csv \
              "SELECT csv_id, posted_at FROM posts WHERE status='posted' AND DATE(posted_at) = date('now', '+9 hours')" \
              | tail -n +2 >> posted_history.csv

            # 重複を削除
            sort -u posted_history.csv -o posted_history.csv.tmp
            mv posted_history.csv.tmp posted_history.csv

            # ヘッダーを先頭に追加
            (echo "csv_id,posted_at" && tail -n +2 posted_history.csv | sort -u) > posted_history.csv.tmp
            mv posted_history.csv.tmp posted_history.csv

            # 2. 投稿済みの csv_id を取得
            POSTED_IDS=$(sqlite3 threads.db -csv \
              "SELECT csv_id FROM posts WHERE status='posted' AND DATE(posted_at) = date('now', '+9 hours')" \
              | tr '\n' ',' | sed 's/,$//')

            if [ -n "$POSTED_IDS" ]; then
              echo "📝 投稿済みIDをCSVから削除: $POSTED_IDS"

              # 3. posts_schedule.csv から投稿済みの行を削除
              python3 cleanup_csv.py "$POSTED_IDS"
            fi

            # 4. データベース、CSV、履歴ファイルをコミット
            if ! git diff --quiet posted_history.csv posts_schedule.csv threads.db 2>/dev/null || [ -n "$(git ls-files --others --exclude-standard threads.db)" ]; then
              POSTED_COUNT=$(tail -n +2 posted_history.csv | wc -l | tr -d ' ')
              REMAINING_COUNT=$(tail -n +2 posts_schedule.csv | wc -l | tr -d ' ')

              git add posted_history.csv posts_schedule.csv threads.db
              git commit -m "Update: Posted ${POSTED_COUNT} total, ${REMAINING_COUNT} remaining [auto]"
              git push origin automation
              echo "✅ データベースと履歴を automation ブランチに保存しました"
            else
              echo "📝 変更がないため、コミットをスキップします"
            fi
          fi

  # PDCAレポート生成ジョブ（3日ごと or 手動）
  pdca-report:
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '0 11 */3 * *') ||
      (github.event_name == 'workflow_dispatch' &&
       (github.event.inputs.mode == 'pdca' || github.event.inputs.mode == 'full-cycle'))
    
    steps:
      - name: リポジトリをチェックアウト (automation ブランチ)
        uses: actions/checkout@v3
        with:
          ref: automation
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Python環境をセットアップ
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: 依存関係をインストール
        run: pip install requests

      - name: Git設定
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: PDCAレポートを生成
        run: python threads_sqlite.py pdca
        env:
          THREADS_ACCESS_TOKEN: ${{ secrets.THREADS_ACCESS_TOKEN }}
          THREADS_USER_ID: ${{ secrets.THREADS_USER_ID }}

      - name: レポートファイルをコミット
        run: |
          if [ -f pdca_report.md ]; then
            git add pdca_report.md
            git diff --quiet && git diff --staged --quiet || git commit -m "📊 Update PDCA report [auto]"
            git push origin automation || true
          fi
      
      - name: GitHub Issueにレポートを投稿
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            // レポートファイルを読み込み
            let reportContent = '';
            try {
              reportContent = fs.readFileSync('pdca_report.md', 'utf8');
            } catch (error) {
              reportContent = '⚠️ レポートの生成に失敗しました。\n\nエラー: ' + error.message;
            }
            
            // Issueを作成
            const date = new Date().toLocaleDateString('ja-JP');
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `📊 PDCA レポート - ${date}`,
              body: reportContent,
              labels: ['pdca-report', 'analytics']
            });
      
      - name: 分析結果を通知（オプション）
        if: always()
        run: |
          echo "✅ PDCAレポートが生成されました"
          echo "📋 Issuesタブで確認してください"
          cat pdca_report.md || echo "レポートファイルが見つかりません"

  # 毎朝のレポート投稿ジョブ（毎日9時 JST）
  daily-report:
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'schedule' && github.event.schedule == '0 0 * * *') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'daily-report')

    steps:
      - name: リポジトリをチェックアウト (main ブランチ)
        uses: actions/checkout@v3
        with:
          ref: main
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Python環境をセットアップ
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: 依存関係をインストール
        run: pip install requests python-dotenv

      - name: データベースを復元（automationブランチから）
        run: |
          # automationブランチからthreads.dbを取得
          git fetch origin automation
          git checkout origin/automation -- threads.db || echo "⚠️ データベースが見つかりません"

          if [ -f threads.db ]; then
            echo "✅ データベースを復元しました"
          else
            echo "📦 新規データベースを作成します"
            python3 migrate_to_sqlite.py init
            python3 threads_sqlite.py import --csv posts_schedule.csv
          fi

      - name: 毎朝のレポートを生成・投稿
        run: python3 threads_sqlite.py daily-report
        env:
          THREADS_ACCESS_TOKEN: ${{ secrets.THREADS_ACCESS_TOKEN }}
          THREADS_USER_ID: ${{ secrets.THREADS_USER_ID }}

      - name: データベースをautomationブランチに保存
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # automationブランチに切り替え
          git fetch origin automation
          git checkout automation

          # データベースを追加
          git add threads.db

          if ! git diff --staged --quiet; then
            git commit -m "Update: Daily report posted [auto]"
            git push origin automation
            echo "✅ データベースをautomationブランチに保存しました"
          else
            echo "📝 変更がないため、コミットをスキップします"
          fi
