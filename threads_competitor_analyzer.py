#!/usr/bin/env python3
"""
Threadsç«¶åˆåˆ†æãƒ»æŠ•ç¨¿æˆ¦ç•¥ãƒ„ãƒ¼ãƒ«

å®Ÿéš›ã®Threads APIä»•æ§˜ã«åŸºã¥ã„ãŸå®Ÿè£…:
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢API (GET /keyword_search)
- å…¬é–‹æŠ•ç¨¿ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆå–å¾—
- ç«¶åˆåˆ†æã¨ãƒˆãƒ¬ãƒ³ãƒ‰æŠŠæ¡
"""

import requests
import pandas as pd
import time
from datetime import datetime, timedelta
from collections import Counter, defaultdict
import os
from dotenv import load_dotenv

load_dotenv()

class ThreadsCompetitorAnalyzer:
    def __init__(self, access_token=None):
        self.token = access_token or os.getenv('THREADS_ACCESS_TOKEN')
        self.base_url = 'https://graph.threads.net/v1.0'
        self.rate_limit_remaining = 500  # 7æ—¥é–“ã§500ã‚¯ã‚¨ãƒª

    def keyword_search(self, keyword, since=None, until=None, limit=50):
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢API

        å…¬å¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: GET /keyword_search

        Parameters:
        - keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        - since: Unix timestamp (é–‹å§‹æ—¥æ™‚)
        - until: Unix timestamp (çµ‚äº†æ—¥æ™‚)
        - limit: å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50ï¼‰

        Returns:
        - List of threads
        """
        url = f"{self.base_url}/keyword_search"
        params = {
            'q': keyword,
            'access_token': self.token,
            'limit': limit,
            'fields': 'id,text,username,timestamp,permalink,media_type,media_url,alt_text'
        }

        if since:
            params['since'] = since
        if until:
            params['until'] = until

        try:
            response = requests.get(url, params=params)
            response.raise_for_status()

            self.rate_limit_remaining -= 1
            print(f"âœ“ Found {len(response.json().get('data', []))} threads for '{keyword}' (Rate limit: {self.rate_limit_remaining}/500)")

            return response.json().get('data', [])
        except requests.exceptions.HTTPError as e:
            print(f"âœ— API Error: {e}")
            print(f"Response: {response.text}")
            return []

    def get_thread_insights(self, thread_id):
        """
        æŠ•ç¨¿ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å–å¾—

        å…¬å¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: GET /{thread_id}/insights

        ãƒ¡ãƒˆãƒªã‚¯ã‚¹: views, likes, replies, reposts, quotes, shares, clicks
        """
        url = f"{self.base_url}/{thread_id}/insights"
        params = {
            'metric': 'views,likes,replies,reposts,quotes,shares',  # clicks ã¯æœ‰æ–™ãƒ—ãƒ©ãƒ³ã®ã¿
            'access_token': self.token
        }

        try:
            response = requests.get(url, params=params)
            response.raise_for_status()

            data = response.json().get('data', [])
            metrics = {}
            for item in data:
                metric_name = item.get('name')
                values = item.get('values', [{}])
                metrics[metric_name] = values[0].get('value', 0) if values else 0

            return metrics
        except requests.exceptions.HTTPError:
            # å…¬é–‹æŠ•ç¨¿ã§ã‚‚è‡ªåˆ†ä»¥å¤–ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã¯å–å¾—ã§ããªã„å¯èƒ½æ€§
            return {}

    def analyze_keyword_trends(self, keywords, days=7):
        """
        è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

        Parameters:
        - keywords: List[str] - åˆ†æã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        - days: int - éå»ä½•æ—¥åˆ†ã‚’åˆ†æã™ã‚‹ã‹

        Returns:
        - DataFrame with trend analysis
        """
        print("\n" + "="*70)
        print(f"ğŸ“Š Keyword Trend Analysis (Past {days} days)")
        print("="*70 + "\n")

        # æ™‚é–“ç¯„å›²ã‚’è¨­å®š
        until_time = int(datetime.now().timestamp())
        since_time = int((datetime.now() - timedelta(days=days)).timestamp())

        all_results = []

        for keyword in keywords:
            print(f"\nğŸ” Analyzing: '{keyword}'")

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            threads = self.keyword_search(keyword, since=since_time, until=until_time, limit=100)

            if not threads:
                print(f"  No threads found for '{keyword}'")
                continue

            # çµ±è¨ˆæƒ…å ±ã‚’é›†è¨ˆ
            total_threads = len(threads)
            usernames = [t.get('username') for t in threads]
            username_counts = Counter(usernames)

            # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ
            media_types = Counter([t.get('media_type', 'TEXT') for t in threads])

            # æ–‡å­—æ•°ã®åˆ†æ
            text_lengths = [len(t.get('text', '')) for t in threads]
            avg_length = sum(text_lengths) / len(text_lengths) if text_lengths else 0

            # ãƒˆãƒƒãƒ—ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼
            top_contributors = username_counts.most_common(5)

            result = {
                'keyword': keyword,
                'total_posts': total_threads,
                'avg_text_length': avg_length,
                'media_types': dict(media_types),
                'top_contributors': top_contributors,
                'posts_per_day': total_threads / days
            }

            all_results.append(result)

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            time.sleep(1)

            # çµæœè¡¨ç¤º
            print(f"  ğŸ“ˆ Posts: {total_threads} ({result['posts_per_day']:.1f}/day)")
            print(f"  ğŸ“ Avg Length: {avg_length:.0f} chars")
            print(f"  ğŸ¨ Media: {media_types}")
            print(f"  ğŸ‘¤ Top: @{top_contributors[0][0]} ({top_contributors[0][1]} posts)")

        # DataFrameåŒ–
        df = pd.DataFrame(all_results)

        print("\n" + "="*70)
        print("ğŸ“Š Summary")
        print("="*70)
        print(df[['keyword', 'total_posts', 'avg_text_length', 'posts_per_day']])

        return df

    def discover_popular_posts(self, keyword, min_engagement=0):
        """
        äººæ°—æŠ•ç¨¿ã®ç™ºè¦‹

        æ³¨æ„: ä»–äººã®æŠ•ç¨¿ã®ã‚¤ãƒ³ã‚µã‚¤ãƒˆã¯å–å¾—ã§ããªã„å¯èƒ½æ€§ãŒé«˜ã„
        ãã®ãŸã‚ã€æŠ•ç¨¿ã®å†…å®¹åˆ†æã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹
        """
        print(f"\nğŸ”¥ Discovering popular posts for: '{keyword}'")

        # éå»7æ—¥é–“ã®æŠ•ç¨¿ã‚’å–å¾—
        since_time = int((datetime.now() - timedelta(days=7)).timestamp())
        threads = self.keyword_search(keyword, since=since_time, limit=100)

        if not threads:
            print("No threads found")
            return pd.DataFrame()

        analysis_data = []

        for thread in threads:
            thread_id = thread.get('id')
            text = thread.get('text', '')
            username = thread.get('username')
            timestamp = thread.get('timestamp')
            permalink = thread.get('permalink')
            media_type = thread.get('media_type', 'TEXT')

            # ã‚¤ãƒ³ã‚µã‚¤ãƒˆå–å¾—ã‚’è©¦ã¿ã‚‹ï¼ˆè‡ªåˆ†ã®æŠ•ç¨¿ã®ã¿æˆåŠŸï¼‰
            insights = self.get_thread_insights(thread_id)

            analysis_data.append({
                'thread_id': thread_id,
                'username': username,
                'text': text[:100],
                'full_text': text,
                'timestamp': timestamp,
                'permalink': permalink,
                'media_type': media_type,
                'text_length': len(text),
                'has_media': media_type != 'TEXT',
                'views': insights.get('views', 0),
                'likes': insights.get('likes', 0),
                'replies': insights.get('replies', 0),
                'reposts': insights.get('reposts', 0),
                'quotes': insights.get('quotes', 0),
                'shares': insights.get('shares', 0)
            })

            time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

        df = pd.DataFrame(analysis_data)

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if df['views'].sum() > 0:
            df['engagement_rate'] = (df['likes'] + df['replies'] + df['reposts']) / df['views'].replace(0, 1) * 100
            df = df.sort_values('engagement_rate', ascending=False)

        print(f"\nâœ“ Analyzed {len(df)} posts")

        return df

    def content_pattern_analysis(self, keyword, days=30):
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

        - æŠ•ç¨¿ã®ãƒˆãƒ¼ãƒ³ï¼ˆç–‘å•å½¢ã€æ–­å®šå½¢ãªã©ï¼‰
        - æ–‡å­—æ•°åˆ†å¸ƒ
        - çµµæ–‡å­—ã®ä½¿ç”¨
        - ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®æœ‰ç„¡
        """
        print(f"\nğŸ“ Content Pattern Analysis: '{keyword}'")

        since_time = int((datetime.now() - timedelta(days=days)).timestamp())
        threads = self.keyword_search(keyword, since=since_time, limit=200)

        if not threads:
            return {}

        patterns = {
            'has_question': 0,
            'has_emoji': 0,
            'has_hashtag': 0,
            'has_url': 0,
            'short_form': 0,  # <100æ–‡å­—
            'medium_form': 0,  # 100-300æ–‡å­—
            'long_form': 0,  # >300æ–‡å­—
        }

        for thread in threads:
            text = thread.get('text', '')

            if '?' in text or 'ï¼Ÿ' in text:
                patterns['has_question'] += 1

            # çµµæ–‡å­—æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if any(ord(c) > 127 for c in text):
                patterns['has_emoji'] += 1

            if '#' in text:
                patterns['has_hashtag'] += 1

            if 'http' in text:
                patterns['has_url'] += 1

            text_len = len(text)
            if text_len < 100:
                patterns['short_form'] += 1
            elif text_len < 300:
                patterns['medium_form'] += 1
            else:
                patterns['long_form'] += 1

        total = len(threads)
        percentages = {k: (v/total)*100 for k, v in patterns.items()}

        print(f"\n  Total analyzed: {total} posts")
        print(f"  Question format: {percentages['has_question']:.1f}%")
        print(f"  With emoji: {percentages['has_emoji']:.1f}%")
        print(f"  With hashtag: {percentages['has_hashtag']:.1f}%")
        print(f"  With URL: {percentages['has_url']:.1f}%")
        print(f"  Short (<100): {percentages['short_form']:.1f}%")
        print(f"  Medium (100-300): {percentages['medium_form']:.1f}%")
        print(f"  Long (>300): {percentages['long_form']:.1f}%")

        return percentages

    def generate_posting_strategy(self, keywords, days=14):
        """
        æŠ•ç¨¿æˆ¦ç•¥ã®ç”Ÿæˆ

        è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†æã—ã¦ã€åŠ¹æœçš„ãªæŠ•ç¨¿æˆ¦ç•¥ã‚’ææ¡ˆ
        """
        print("\n" + "="*70)
        print("ğŸ¯ POSTING STRATEGY GENERATOR")
        print("="*70 + "\n")

        strategies = []

        for keyword in keywords:
            print(f"\nğŸ“Š Analyzing '{keyword}'...")

            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trend_df = self.analyze_keyword_trends([keyword], days=days)

            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            patterns = self.content_pattern_analysis(keyword, days=days)

            if not trend_df.empty:
                strategy = {
                    'keyword': keyword,
                    'recommended_frequency': f"{trend_df.iloc[0]['posts_per_day']:.1f} posts/day",
                    'optimal_length': f"{trend_df.iloc[0]['avg_text_length']:.0f} chars",
                    'use_question_format': patterns.get('has_question', 0) > 30,
                    'include_emoji': patterns.get('has_emoji', 0) > 50,
                    'include_hashtag': patterns.get('has_hashtag', 0) > 20,
                    'content_type': 'Short' if patterns.get('short_form', 0) > 50 else 'Medium'
                }

                strategies.append(strategy)

            time.sleep(2)

        # æˆ¦ç•¥ã‚µãƒãƒªãƒ¼
        print("\n" + "="*70)
        print("ğŸ“‹ STRATEGY RECOMMENDATIONS")
        print("="*70 + "\n")

        for strategy in strategies:
            print(f"Keyword: '{strategy['keyword']}'")
            print(f"  Frequency: {strategy['recommended_frequency']}")
            print(f"  Length: {strategy['optimal_length']}")
            print(f"  Question format: {'âœ“' if strategy['use_question_format'] else 'âœ—'}")
            print(f"  Emoji: {'âœ“' if strategy['include_emoji'] else 'âœ—'}")
            print(f"  Hashtag: {'âœ“' if strategy['include_hashtag'] else 'âœ—'}")
            print(f"  Type: {strategy['content_type']}-form content")
            print()

        return strategies


def main():
    """ä½¿ç”¨ä¾‹"""

    # åˆæœŸåŒ–
    analyzer = ThreadsCompetitorAnalyzer()

    # åˆ†æã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚ãªãŸã®ãƒ‹ãƒƒãƒã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
    keywords = [
        'å‰¯æ¥­',
        'ä»•äº‹è¡“',
        'æœæ´»',
        'ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹',
        'æ™‚é–“ç®¡ç†'
    ]

    # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    print("\nğŸ” STEP 1: Keyword Trend Analysis")
    trend_df = analyzer.analyze_keyword_trends(keywords, days=7)
    trend_df.to_csv('threads_keyword_trends.csv', index=False, encoding='utf-8-sig')

    # 2. äººæ°—æŠ•ç¨¿ã®ç™ºè¦‹
    print("\nğŸ”¥ STEP 2: Popular Posts Discovery")
    for keyword in keywords[:2]:  # æœ€åˆã®2ã¤ã ã‘ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰
        popular_df = analyzer.discover_popular_posts(keyword)
        if not popular_df.empty:
            popular_df.to_csv(f'threads_popular_{keyword}.csv', index=False, encoding='utf-8-sig')
        time.sleep(3)

    # 3. æŠ•ç¨¿æˆ¦ç•¥ã®ç”Ÿæˆ
    print("\nğŸ¯ STEP 3: Posting Strategy Generation")
    strategies = analyzer.generate_posting_strategy(keywords[:3], days=14)

    # æˆ¦ç•¥ã‚’CSVã«ä¿å­˜
    pd.DataFrame(strategies).to_csv('threads_posting_strategy.csv', index=False, encoding='utf-8-sig')

    print("\nâœ… Analysis complete! Check the generated CSV files.")
    print(f"ğŸ“Š Rate limit remaining: {analyzer.rate_limit_remaining}/500 (7-day window)")


if __name__ == '__main__':
    main()
